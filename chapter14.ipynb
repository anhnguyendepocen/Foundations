{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Processing Pipelines\n",
    "\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, f_regression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  1  0  0  0\n",
       "1  0  1  0  0\n",
       "2  0  0  1  0\n",
       "3  1  0  0  0\n",
       "4  0  1  0  0\n",
       "5  0  0  0  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(['A', 'B', 'C', 'A', 'B', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Linear regression: scaling is not required ==\n",
      "Coefficients: [ 1.05421281e-04  1.13551103e+02  9.78705905e+01  1.60747221e+01\n",
      " -7.23145329e-01] -113550117.82706574\n",
      "Test R2:0.77\n",
      "---------------------------------------\n",
      "== Lasso without scaling ==\n",
      "Coefficients: [8.24902914e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00] 985.9940020104059\n",
      "Test R2:0.10\n",
      "---------------------------------------\n",
      "== Lasso with scaling ==\n",
      "Coefficients: [ 90.49136877 107.71407934  93.17561877  11.84506925  -0.        ] 982.3027936469599\n",
      "Test R2:0.77\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "np.random.seed(42)\n",
    "n_samples, n_features, n_features_info = 100, 5, 3\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "beta = np.zeros(n_features)\n",
    "beta[:n_features_info] = 1\n",
    "Xbeta = np.dot(X, beta)\n",
    "eps = np.random.randn(n_samples)\n",
    "y = Xbeta + eps\n",
    "\n",
    "X[:, 0] *= 1e6 # inflate the first feature\n",
    "X[:, 1] += 1e6 # bias the second feature\n",
    "y = 100 * y + 1000 # bias and scale the output\n",
    "\n",
    "print(\"== Linear regression: scaling is not required ==\")\n",
    "model =lm.LinearRegression()\n",
    "model.fit(X, y)\n",
    "print(\"Coefficients:\", model.coef_, model.intercept_)\n",
    "print(\"Test R2:%.2f\" % cross_val_score(estimator=model, X=X, y=y, cv=5).mean())\n",
    "\n",
    "print('---------------------------------------')\n",
    "print(\"== Lasso without scaling ==\")\n",
    "model = lm.LassoCV(cv=5)\n",
    "model.fit(X, y)\n",
    "print(\"Coefficients:\", model.coef_, model.intercept_)\n",
    "print(\"Test R2:%.2f\" % cross_val_score(estimator=model, X=X, y=y, cv=5).mean())\n",
    "\n",
    "print('---------------------------------------')\n",
    "print(\"== Lasso with scaling ==\")\n",
    "model = lm.LassoCV(cv=5)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Xc = scaler.fit(X).transform(X)\n",
    "model.fit(Xc, y)\n",
    "print(\"Coefficients:\", model.coef_, model.intercept_)\n",
    "print(\"Test R2:%.2f\" % cross_val_score(estimator=model, X=Xc, y=y, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test r2:0.77\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessing.StandardScaler(), lm.LassoCV(cv=5))\n",
    "\n",
    "# or\n",
    "from sklearn.pipeline import Pipeline\n",
    "model = Pipeline([('standardscaler', preprocessing.StandardScaler()), ('lassocv', lm.LassoCV(cv=5))])\n",
    "\n",
    "scores = cross_val_score(estimator=model, X=X, y=y, cv=5)\n",
    "print(\"Test r2:%.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova filter + linear regression, test r2:0.72\n",
      "Standardize + Lasso, test r2:0.64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_samples, n_features, n_features_info = 100, 100, 3\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "beta = np.zeros(n_features)\n",
    "beta[:n_features_info] = 1\n",
    "Xbeta = np.dot(X, beta)\n",
    "eps = np.random.randn(n_samples)\n",
    "y = Xbeta + eps\n",
    "\n",
    "X[:, 0] *= 1e6 # inflate the first feature\n",
    "X[:, 1] += 1e6 # bias the second feature\n",
    "y = 100 * y + 1000 # bias and scale the output\n",
    "\n",
    "model = Pipeline([('anova', SelectKBest(f_regression, k=3)), ('lm', lm.LinearRegression())])\n",
    "scores = cross_val_score(estimator=model, X=X, y=y, cv=5)\n",
    "print(\"Anova filter + linear regression, test r2:%.2f\" % scores.mean())\n",
    "\n",
    "model = Pipeline([('standardscaler', preprocessing.StandardScaler()), ('lassocv', lm.LassoCV(cv=5))])\n",
    "scores = cross_val_score(estimator=model, X=X, y=y, cv=5)\n",
    "print(\"Standardize + Lasso, test r2:%.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression pipelines with CV for parameters selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 3.2866820167645523\n",
      "=============================\n",
      "== Basic linear regression ==\n",
      "=============================\n",
      "Test r2:0.30\n",
      "==============================================\n",
      "== Scaler + anova filter + ridge regression ==\n",
      "==============================================\n",
      "----------------------------\n",
      "-- Parallelize inner loop --\n",
      "----------------------------\n",
      "CPU times: user 10 s, sys: 5.49 s, total: 15.5 s\n",
      "Wall time: 7.62 s\n",
      "Test r2:0.86\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 33.2 ms, sys: 34.3 ms, total: 67.5 ms\n",
      "Wall time: 9.08 s\n",
      "Test r2:0.86\n",
      "=====================================\n",
      "== Scaler + Elastic-net regression ==\n",
      "=====================================\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 10.6 ms, sys: 9.18 ms, total: 19.8 ms\n",
      "Wall time: 4.63 s\n",
      "Test r2:0.82\n",
      "-----------------------------------------------\n",
      "-- Parallelize outer loop + built-in CV--------\n",
      "-- Remark: scaler is only done on outer loop --\n",
      "-----------------------------------------------\n",
      "CPU times: user 1.28 s, sys: 4.74 ms, total: 1.29 s\n",
      "Wall time: 1.28 s\n",
      "Test r2:0.82\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "n_samples, n_features, noise_sd = 100, 100, 20\n",
    "X, y, coef = datasets.make_regression(n_samples=n_samples, n_features=n_features, noise=noise_sd, \n",
    "                                      n_informative=5, random_state=42, coef=True)\n",
    "\n",
    "# Use this to tune the noise parameter such that snr < 5\n",
    "print(\"SNR:\", np.std(np.dot(X, coef)) / noise_sd)\n",
    "\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"== Basic linear regression ==\")\n",
    "print(\"=============================\")\n",
    "\n",
    "scores = cross_val_score(estimator=lm.LinearRegression(), X=X, y=y, cv=5)\n",
    "print(\"Test r2:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(\"== Scaler + anova filter + ridge regression ==\")\n",
    "print(\"==============================================\")\n",
    "\n",
    "anova_ridge = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('selectkbest', SelectKBest(f_regression)),\n",
    "    ('ridge', lm.Ridge())\n",
    "])\n",
    "\n",
    "param_grid = {'selectkbest__k':np.arange(10, 110, 10),\n",
    "              'ridge__alpha':[.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "\n",
    "# Expect execution in ipython, for python remove the %time\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize inner loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid, n_jobs=-1)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5)\n",
    "print(\"Test r2:%.2f\" % scores.mean())\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5, n_jobs=-1)\n",
    "print(\"Test r2:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"== Scaler + Elastic-net regression ==\")\n",
    "print(\"=====================================\")\n",
    "alphas = [.0001, .001, .01, .1, 1, 10, 100, 1000]\n",
    "l1_ratio = [.1, .5, .9]\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "enet = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('enet', lm.ElasticNet(max_iter=10000)),\n",
    "])\n",
    "param_grid = {'enet__alpha':alphas ,\n",
    "'enet__l1_ratio':l1_ratio}\n",
    "enet_cv = GridSearchCV(enet, cv=5, param_grid=param_grid)\n",
    "%time scores = cross_val_score(estimator=enet_cv, X=X, y=y, cv=5, n_jobs=-1)\n",
    "print(\"Test r2:%.2f\" % scores.mean())\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-- Parallelize outer loop + built-in CV--------\")\n",
    "print(\"-- Remark: scaler is only done on outer loop --\")\n",
    "print(\"-----------------------------------------------\")\n",
    "enet_cv = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('enet', lm.ElasticNetCV(max_iter=10000, l1_ratio=l1_ratio, alphas=alphas, cv=5)),\n",
    "])\n",
    "%time scores = cross_val_score(estimator=enet_cv, X=X, y=y, cv=5)\n",
    "print(\"Test r2:%.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipelines with CV for parameters selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "== Basic logistic regression ==\n",
      "=============================\n",
      "Test bACC:0.76\n",
      "=======================================================\n",
      "== Scaler + anova filter + ridge logistic regression ==\n",
      "=======================================================\n",
      "----------------------------\n",
      "-- Parallelize inner loop --\n",
      "----------------------------\n",
      "CPU times: user 20.3 s, sys: 8.49 ms, total: 20.3 s\n",
      "Wall time: 20.4 s\n",
      "Test bACC:0.78\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 21.3 s, sys: 6.9 ms, total: 21.3 s\n",
      "Wall time: 21.3 s\n",
      "Test bACC:0.78\n",
      "=======================================================\n",
      "== Scaler + anova filter + ridge logistic regression ==\n",
      "=======================================================\n",
      "----------------------------\n",
      "-- Parallelize inner loop --\n",
      "----------------------------\n",
      "CPU times: user 20.5 s, sys: 0 ns, total: 20.5 s\n",
      "Wall time: 20.5 s\n",
      "Test bACC:0.78\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 20.8 s, sys: 3.57 ms, total: 20.8 s\n",
      "Wall time: 20.8 s\n",
      "Test bACC:0.78\n",
      "========================================\n",
      "== Scaler + lasso logistic regression ==\n",
      "========================================\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 1.16 s, sys: 7.67 ms, total: 1.16 s\n",
      "Wall time: 1.16 s\n",
      "Test bACC:0.72\n",
      "-----------------------------------------------\n",
      "-- Parallelize outer loop + built-in CV--------\n",
      "-- Remark: scaler is only done on outer loop --\n",
      "-----------------------------------------------\n",
      "CPU times: user 429 ms, sys: 60 µs, total: 430 ms\n",
      "Wall time: 430 ms\n",
      "Test bACC:0.75\n",
      "=============================================\n",
      "== Scaler + Elasticnet logistic regression ==\n",
      "=============================================\n",
      "----------------------------\n",
      "-- Parallelize outer loop --\n",
      "----------------------------\n",
      "CPU times: user 3.46 s, sys: 3.77 ms, total: 3.46 s\n",
      "Wall time: 3.49 s\n",
      "Test bACC:0.74\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "n_samples, n_features, noise_sd = 100, 100, 20\n",
    "X, y = datasets.make_classification(n_samples=n_samples, n_features=n_features, \n",
    "                                    n_informative=5, random_state=42)\n",
    "\n",
    "def balanced_acc(estimator, X, y):\n",
    "    '''Balanced acuracy scorer'''\n",
    "    return metrics.recall_score(y, estimator.predict(X), average=None).mean()\n",
    "\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"== Basic logistic regression ==\")\n",
    "print(\"=============================\")\n",
    "scores = cross_val_score(estimator=lm.LogisticRegression(C=1e8, class_weight='balanced', solver='lbfgs'), \n",
    "                         X=X, y=y, cv=5, scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "print(\"=======================================================\")\n",
    "print(\"== Scaler + anova filter + ridge logistic regression ==\")\n",
    "print(\"=======================================================\")\n",
    "anova_ridge = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('selectkbest', SelectKBest(f_classif)),\n",
    "    ('ridge', lm.LogisticRegression(penalty='l2', class_weight='balanced', solver='lbfgs'))\n",
    "])\n",
    "param_grid = {'selectkbest__k':np.arange(10, 110, 10), \n",
    "              'ridge__C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Expect execution in ipython, for python remove the %time\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize inner loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid, scoring=balanced_acc, n_jobs=-1)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5, scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid, scoring=balanced_acc)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5, scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "print(\"=======================================================\")\n",
    "print(\"== Scaler + anova filter + ridge logistic regression ==\")\n",
    "print(\"=======================================================\")\n",
    "anova_ridge = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('selectkbest', SelectKBest(f_classif)),\n",
    "    ('ridge', lm.LogisticRegression(penalty='l2', class_weight='balanced', solver='lbfgs'))\n",
    "])\n",
    "param_grid = {'selectkbest__k':np.arange(10, 110, 10), \n",
    "              'ridge__C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Expect execution in ipython, for python remove the %time\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize inner loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid, scoring=balanced_acc, n_jobs=-1)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5, scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "anova_ridge_cv = GridSearchCV(anova_ridge, cv=5, param_grid=param_grid,\n",
    "                              scoring=balanced_acc)\n",
    "%time scores = cross_val_score(estimator=anova_ridge_cv, X=X, y=y, cv=5, scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"== Scaler + lasso logistic regression ==\")\n",
    "print(\"========================================\")\n",
    "Cs = np.array([.0001, .001, .01, .1, 1, 10, 100, 1000, 10000])\n",
    "alphas = 1 / Cs\n",
    "l1_ratio = [.1, .5, .9]\n",
    "\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "lasso = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('lasso', lm.LogisticRegression(penalty='l1', class_weight='balanced')),\n",
    "])\n",
    "param_grid = {'lasso__C':Cs}\n",
    "enet_cv = GridSearchCV(lasso, cv=5, param_grid=param_grid, scoring=balanced_acc)\n",
    "%time scores = cross_val_score(estimator=enet_cv, X=X, y=y, cv=5,scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-- Parallelize outer loop + built-in CV--------\")\n",
    "print(\"-- Remark: scaler is only done on outer loop --\")\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "lasso_cv = Pipeline([\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('lasso', lm.LogisticRegressionCV(Cs=Cs)),\n",
    "])\n",
    "%time scores = cross_val_score(estimator=lasso_cv, X=X, y=y, cv=5)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())\n",
    "\n",
    "\n",
    "print(\"=============================================\")\n",
    "print(\"== Scaler + Elasticnet logistic regression ==\")\n",
    "print(\"=============================================\")\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"-- Parallelize outer loop --\")\n",
    "print(\"----------------------------\")\n",
    "enet = Pipeline([('standardscaler', preprocessing.StandardScaler()),\n",
    "                 ('enet', lm.SGDClassifier(loss=\"log\", penalty=\"elasticnet\",\n",
    "                                           alpha=0.0001, l1_ratio=0.15, class_weight='balanced')),\n",
    "])\n",
    "param_grid = {'enet__alpha':alphas,'enet__l1_ratio':l1_ratio}\n",
    "enet_cv = GridSearchCV(enet, cv=5, param_grid=param_grid, scoring=balanced_acc)\n",
    "%time scores = cross_val_score(estimator=enet_cv, X=X, y=y, cv=5,scoring=balanced_acc)\n",
    "print(\"Test bACC:%.2f\" % scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
